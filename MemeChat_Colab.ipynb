{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¤– DialoGPT MemeChat\n",
    "### Author: Charan Siddarth  \n",
    "### Year: 2025\n",
    "\n",
    "Welcome to **DialoGPT MemeChat** â€” a meme-style AI chatbot built with Hugging Face Transformers and Gradio.\n",
    "\n",
    "ğŸ’¬ It replies with humor, emojis, and internet slang.\n",
    "\n",
    "âš™ï¸ This notebook will automatically create a Gradio web app (with a public link) that you can chat with right here in Google Colab!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ Step 1 â€“ Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers gradio torch --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¤– Step 2 â€“ Import Libraries and Load Model"
   ]
  }

  ,
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch, gradio as gr\n",
    "\n",
    "MODEL_NAME = 'microsoft/DialoGPT-medium'\n",
    "print(f'ğŸ”„ Loading model: {MODEL_NAME} ...')\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
    "print('âœ… Model loaded successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ­ Step 3 â€“ Define Meme-Style Chatbot Logic"
   ]
  }

  ,
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def meme_response(text):\n",
    "    meme_suffixes = ['ğŸ˜‚','ğŸ”¥','ğŸ’€','ğŸ¤£','ğŸ˜','ğŸ¤–','âœ¨','lol','bruh','no cap','fr fr','ğŸ’¯','ngl']\n",
    "    return text + ' ' + random.choice(meme_suffixes)\n",
    "\n",
    "def chat_fn(message, history):\n",
    "    history_text = ''\n",
    "    for human, bot in history:\n",
    "        history_text += f'User: {human}\\nBot: {bot}\\n'\n",
    "    prompt = history_text + f'User: {message}\\nBot:'\n",
    "    input_ids = tokenizer.encode(prompt + tokenizer.eos_token, return_tensors='pt')\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=250,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        temperature=0.9,\n",
    "        top_p=0.92\n",
    "    )\n",
    "    reply = tokenizer.decode(output[:, input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
    "    return meme_response(reply)\n",
    "\n",
    "# Launch Gradio UI â€“ auto-share enabled for Colab\n",
    "gr.ChatInterface(\n",
    "    fn=chat_fn,\n",
    "    title='DialoGPT MemeChat ğŸ¤–ğŸ”¥',\n",
    "    description='A fun meme-style AI chatbot powered by Hugging Face Transformers.',\n",
    "    type='messages'\n",
    ").launch(share=True)"
   ]
  }

  ,
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… All Set!\n",
    "Once you see the ğŸ”— **public URL** from Gradio above, click it to chat with your bot.\n",
    "\n",
    "When done, stop the cell to end the session.\n",
    "\n",
    "---\n",
    "Â© 2025 Charan Siddarth â€“ MIT License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
